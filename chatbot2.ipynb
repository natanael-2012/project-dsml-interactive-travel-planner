{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_analyze_input(user_input, current_step, task):\n",
    "    \"\"\"\n",
    "    Analyze user input using GPT based on the current step and task.\n",
    "\n",
    "    Parameters:\n",
    "    user_input (str): The input from the user.\n",
    "    current_step (str): The current step in the conversation.\n",
    "    task (str): Specific task for GPT (e.g., \"detect_lock_location\", \"analyze_weather\").\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing detected information, or a boolean result for lock location.\n",
    "    \"\"\"\n",
    "    if task == \"detect_lock_location\":\n",
    "        prompt = f\"Based on the user's input: '{user_input}', does the user want to lock in the location?\"\n",
    "    elif task == \"analyze_weather\":\n",
    "        prompt = f\"Given the travel dates and location, '{user_input}', will the weather be bad for the trip?\"\n",
    "    else:\n",
    "        prompt = f\"Analyze this user input: '{user_input}' during step '{current_step}' and extract relevant details (e.g., dates, interests, etc.).\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4o-mini\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    # Example response structure: Let's assume GPT returns a structured result\n",
    "    gpt_response = response.choices[0].text.strip()\n",
    "\n",
    "    # Return boolean if task is detect_lock_location\n",
    "    if task == \"detect_lock_location\":\n",
    "        return \"yes\" in gpt_response.lower() or \"lock\" in gpt_response.lower()\n",
    "\n",
    "    # For other tasks, return a structured response (adjust according to actual output format)\n",
    "    return gpt_response  # You can further parse it based on task requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_extract_info(user_input, current_step):\n",
    "    \"\"\"\n",
    "    Extract multiple pieces of information from the user's input.\n",
    "    For example, dates, interests, locations, and questions.\n",
    "    \"\"\"\n",
    "    prompt = f\"Analyze this user input: '{user_input}' and extract relevant information such as travel dates, interests, location information, and any questions.\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4o-mini\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    # change this structure and set return type as JSON\n",
    "\n",
    "    # Example structure from GPT: Let's assume it returns structured text like this\n",
    "    # \"Dates: May 15th to May 25th, Interests: beaches, hiking, Location: Puerto Rico\"\n",
    "    gpt_response = response.choices[0].text.strip()\n",
    "\n",
    "    detected_info = {\n",
    "        \"travel_dates\": None,\n",
    "        \"interests\": None,\n",
    "        \"suggested_locations\": None,\n",
    "        \"questions\": None\n",
    "    }\n",
    "    \n",
    "    # Parse the structured response based on how GPT formats its response\n",
    "    if \"Dates\" in gpt_response:\n",
    "        detected_info[\"travel_dates\"] = gpt_response.split(\"Dates: \")[1].split(\",\")[0]  # Example parsing\n",
    "    if \"Interests\" in gpt_response:\n",
    "        detected_info[\"interests\"] = gpt_response.split(\"Interests: \")[1].split(\",\")[0]\n",
    "    if \"Location\" in gpt_response:\n",
    "        detected_info[\"suggested_locations\"] = gpt_response.split(\"Location: \")[1].split(\",\")[0]\n",
    "\n",
    "    return detected_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weather_dependent(location):\n",
    "    \"\"\"\n",
    "    Ask GPT whether a location is weather dependent or not.\n",
    "    \"\"\"\n",
    "    prompt = f\"Is the location '{location}' highly dependent on weather conditions? (e.g., outdoor activities, beach, hiking).\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4o-mini\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    gpt_response = response.choices[0].text.strip()\n",
    "    return \"yes\" in gpt_response.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weather(location, travel_dates):\n",
    "    \"\"\"\n",
    "    Ask GPT or an API to check the weather for the given location and travel dates.\n",
    "    \"\"\"\n",
    "    prompt = f\"Check the weather for {location} on these dates: {travel_dates}. Is it expected to be bad?\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4o-mini\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    gpt_response = response.choices[0].text.strip()\n",
    "    return \"bad\" in gpt_response.lower() or \"rain\" in gpt_response.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_action(user_input):\n",
    "    \"\"\"\n",
    "    Use GPT to detect if the user confirms or rejects an action.\n",
    "    For example, locking a location or proceeding with a decision.\n",
    "    \"\"\"\n",
    "    prompt = f\"Does the user want to confirm this action based on their input: '{user_input}'?\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4o-mini\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    gpt_response = response.choices[0].text.strip()\n",
    "    return \"yes\" in gpt_response.lower() or \"confirm\" in gpt_response.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(user_input, current_step, conversation_state):\n",
    "    \"\"\"\n",
    "    Orchestrates the conversation based on the current step and user input.\n",
    "\n",
    "    Parameters:\n",
    "    user_input (str): The input from the user.\n",
    "    current_step (str): The current step in the conversation.\n",
    "\n",
    "    Returns:\n",
    "    str: The next step in the conversation.\n",
    "    \"\"\"\n",
    "    # Define steps of conversation (flow)\n",
    "    if current_step == \"start\":\n",
    "        \n",
    "        # Get user input and check for details\n",
    "        detected_info = gpt_extract_info(user_input, current_step)          ### fix gpt response format\n",
    "        if detected_info[\"travel_dates\"] and detected_info[\"interests\"]:  # If both dates and interests are detected\n",
    "            conversation_state[\"travel_dates\"] = detected_info[\"dates\"]\n",
    "            conversation_state[\"interests\"] = detected_info[\"interests\"]\n",
    "            return \"suggest_locations\"\n",
    "        elif detected_info[\"travel_dates\"]:  # If only dates are detected\n",
    "            conversation_state[\"travel_dates\"] = detected_info[\"travel_dates\"]\n",
    "            return \"ask_interests\"\n",
    "        elif detected_info[\"interests\"]:  # If only interests are detected\n",
    "            conversation_state[\"interests\"] = detected_info[\"interests\"]\n",
    "        # First step: ask for travel dates\n",
    "        return \"ask_travel_dates\"\n",
    "    \n",
    "    elif current_step == \"received_dates\":\n",
    "        if conversation_state.get(\"interests\"):\n",
    "            # If interests are already detected, suggest locations\n",
    "            return \"suggest_locations\"\n",
    "        # Next step: ask for interests\n",
    "        return \"ask_interests\"\n",
    "    \n",
    "    elif current_step == \"received_interests\":\n",
    "        # save interests\n",
    "        detected_info = gpt_extract_info(user_input, current_step)              #########fix gpt response format\n",
    "        conversation_state[\"interests\"] = detected_info[\"interests\"]\n",
    "\n",
    "        # Now suggest locations based on interests\n",
    "        return \"suggest_locations\"\n",
    "    ########### adding other steps that chatgpt didnt suggest#################\n",
    "    elif current_step == \"received_location\":\n",
    "        current_location = gpt_extract_info(user_input, current_step)   ##### fix gpt response format\n",
    "        conversation_state[\"current_location\"] = current_location\n",
    "        # Answer user questions about location\n",
    "        return \"answer_questions\"\n",
    "    elif current_step == \"ask_lock_location\":\n",
    "        #after answering questions, ask if user wants to lock in location\n",
    "\n",
    "        # use gpt to know if they want to lock in location\n",
    "        ########### GPT ################\n",
    "        want_to_lock = True | False #GPT response\n",
    "        ################################\n",
    "        want_to_lock = confirm_action(user_input)           #########fix gpt response format\n",
    "\n",
    "        #we asked if \"they want to go there.\" if they say yes, we lock in location (temporarily)\n",
    "        \n",
    "        if want_to_lock: #if they want to go there...\n",
    "            # check if location is weather dependant (maybe another gpt call and they respond {\"wheather dependant\": True})\n",
    "            weather_dependant = True | False #GPT response\n",
    "            weather_dependant = is_weather_dependent(conversation_state[\"current_location\"])        # fix gpt response format\n",
    "            if weather_dependant:\n",
    "                #check weather for date\n",
    "                bad_weather = True | False #(bad weather/good weather)\n",
    "                bad_weather = check_weather(conversation_state[\"current_location\"], conversation_state[\"dates\"]) # fix gpt response format\n",
    "                if bad_weather:\n",
    "                    return \"bad_weather\"\n",
    "            else:\n",
    "                return \"lock_location\"\n",
    "            # return \"lock_location?\"\n",
    "        # if they say no, we suggest other locations\n",
    "        else:\n",
    "            return \"suggest_alternatives\" # create new step for this\"\n",
    "    elif current_step == \"lock_or_change\":\n",
    "        # there was bad weather and we asked the user if they wanted to lock the location.\n",
    "        # use gpt to know if they want to lock in location\n",
    "        ########### GPT ################\n",
    "        want_to_lock = True | False #GPT response\n",
    "        ################################\n",
    "        want_to_lock = confirm_action(user_input)           #########fix gpt response format\n",
    "        if want_to_lock:\n",
    "            conversation_state[\"locked_locations\"].append(conversation_state[\"current_location\"])\n",
    "            return \"lock_location\"\n",
    "        else:\n",
    "            return \"suggest_alternatives\"\n",
    "\n",
    "    elif current_step == \"suggest_other_locations\":\n",
    "        # suggest other locations\n",
    "        return \"suggest_locations\"\n",
    "    \n",
    "    elif current_step == \"end_or_suggest_alternatives\":\n",
    "        # we asked the user if the would like to go anywhere else\n",
    "        # use gpt to know if they want to go anywhere else\n",
    "\n",
    "        ########### GPT ################\n",
    "        want_to_go = True | False #GPT response\n",
    "        ################################\n",
    "        want_to_go = confirm_action(user_input)           #########fix gpt response format\n",
    "        if want_to_go:\n",
    "            return \"suggest_locations\"\n",
    "        else:\n",
    "            return \"end_conversation\"\n",
    "        \n",
    "    elif current_step == \"return_list_of_locked_locations\":\n",
    "        return \"give_list\"\n",
    "    ##############################################\n",
    "    else:\n",
    "        # Fall back to default\n",
    "        return \"default_response\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communicator(orchestrator_action, user_input, conversation_state):\n",
    "    \"\"\"\n",
    "    Communicates with the user based on the orchestrator's action.\n",
    "\n",
    "    Parameters:\n",
    "    orchestrator_action (str): The action recommended by the orchestrator.\n",
    "    user_input (str): The input from the user.\n",
    "\n",
    "    Returns:\n",
    "    str: The response to the user.\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "\n",
    "    if orchestrator_action == \"ask_travel_dates\":\n",
    "        # Use GPT-4o-mini to rephrase the question\n",
    "        response= \"Great! When are you planning to travel?\"\n",
    "    elif orchestrator_action == \"ask_interests\":\n",
    "        # GPT-4o-mini rephrasing\n",
    "        response= \"What kind of places do you like to visit? Are you interested in beaches, historic sites, or something else?\"\n",
    "    elif orchestrator_action == \"suggest_locations\":\n",
    "        # Suggest locations based on interests (USE RAG)\n",
    "        if not conversation_state.get(\"suggested_locations\"):\n",
    "            rag_response = db.similarity_search(user_input) | rank_appropriate_locations(user_input) # Placeholder function\n",
    "            conversation_state[\"suggested_locations\"] = rag_response[].   # save suggested locations. Use metadata (landmarks and name)\n",
    "        else:\n",
    "            #get index in which current location is in suggested locations\n",
    "            index = conversation_state[\"suggested_locations\"].index(conversation_state[\"current_location\"])\n",
    "            # delete current location from suggested locations\n",
    "            conversation_state[\"suggested_locations\"].pop(index)\n",
    "            #remove element in index location from rag response\n",
    "            rag_response.pop(index)\n",
    "            \n",
    "        # gpt call to suggest locations. pass rag_response as context\n",
    "        response= \"How about visiting the Castillo San Felipe del Morro in San Juan? It's a beautiful historic site!\"\n",
    "    \n",
    "    ################ adding other responses that chatgpt didnt suggest\n",
    "    elif orchestrator_action == \"answer_questions\":\n",
    "        #### give info about the location\n",
    "        info = find_info_on_location(user_input, conversation_state[\"current_location\"]) # placeholder function. \n",
    "        # Answer user questions about location. ASK IF THEY WISH TO GO THERE\n",
    "        response= \"Yes, you can visit the Castillo San Felipe del Morro in San Juan. It's a historic fort that dates back to the 16th century. Would you like to go there?\"\n",
    "    elif orchestrator_action == \"bad_weather\":\n",
    "        # Inform user about bad weather\n",
    "        response= \"The weather in San Juan is not great for your travel dates. Do you still want to lock in the location?\"\n",
    "    elif orchestrator_action == \"lock_location\": # lock location\n",
    "        # Lock the location\n",
    "        response= \"Got it! I've locked that location for your trip. Would you like to go anywhere else?\"\n",
    "    elif orchestrator_action == \"suggest_alternatives\":\n",
    "        # Suggest alternative locations\n",
    "        response = \"How about visiting the El Yunque National Forest in Puerto Rico? It's a beautiful rainforest with amazing hiking trails!\"\n",
    "    elif orchestrator_action == \"end_conversation\":\n",
    "        # End the conversation\n",
    "        response= \"Great! Enjoy your trip! *wait for list of locked locations*\"\n",
    "    \n",
    "    elif orchestrator_action == \"give_list\":\n",
    "        # Give list of locked locations\n",
    "        # use conversation_state[\"locked_locations\"]\n",
    "        # and use compute_distance_to_list() \n",
    "        response= \"Here are the locations you've locked in: 1. Castillo San Felipe del Morro in San Juan, Puerto Rico. 2. El Yunque National Forest in Puerto Rico. Enjoy your trip!\"\n",
    "    \n",
    "    ############################\n",
    "    \n",
    "    else:\n",
    "        # Default fallback\n",
    "        return \"I'm not sure how to respond. Could you clarify?\"\n",
    "    \n",
    "    conversation_state[\"messages\"].append({\"user\": user_input, \"bot\": response})     #### add response to conversation state (fix \"bot\")\n",
    "\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_step (orchestrator_action):\n",
    "     # Update the flow based on the orchestrator's action\n",
    "    if orchestrator_action == \"ask_travel_dates\":\n",
    "        return \"received_dates\"\n",
    "    elif orchestrator_action == \"ask_interests\":\n",
    "        return \"received_interests\"\n",
    "    elif orchestrator_action == \"suggest_locations\":\n",
    "        #########################\n",
    "        return \"received_location\"\n",
    "    elif orchestrator_action == \"answer_questions\":\n",
    "        return \"ask_lock_location\"\n",
    "    elif orchestrator_action == \"bad_weather\":\n",
    "        return \"lock_or_change\"\n",
    "    elif orchestrator_action == \"lock_location\":\n",
    "        return \"end_or_suggest_alternatives\"\n",
    "\n",
    "    elif orchestrator_action == \"suggest_alternatives\":\n",
    "        return \"suggest_other_locations\"\n",
    "    elif orchestrator_action == \"end_conversation\":\n",
    "        return \"return_list_of_locked_locations\"\n",
    "    elif orchestrator_action == \"give_list\":  \n",
    "        return \"end\"\n",
    "    return \"default_response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user input and flow\n",
    "\n",
    "conversation_state = {\n",
    "    \"travel_dates\": None,\n",
    "    \"interests\": None,\n",
    "    \"locked_location\": [],   # i need to save the coordinates of the locations\n",
    "    \"suggested_locations\": [],\n",
    "    \"current_location\": None,\n",
    "    \"messages\": []  # To store the full conversation history\n",
    "}\n",
    "rag_response = None\n",
    "\n",
    "current_step = \"start\"\n",
    "while current_step != \"end\":\n",
    "    user_input = input(\"You: \")  # Get user input\n",
    "    print(f\"> {user_input}\")\n",
    "    orchestrator_action = orchestrator(user_input, current_step, conversation_state)\n",
    "    response = communicator(orchestrator_action, user_input, conversation_state)\n",
    "    print(f\"Bot: {response}\")\n",
    "    \n",
    "    # Update the flow based on the orchestrator's action\n",
    "    if orchestrator_action == \"ask_travel_dates\":\n",
    "        current_step = \"received_dates\"\n",
    "    elif orchestrator_action == \"ask_interests\":\n",
    "        current_step = \"received_interests\"\n",
    "    elif orchestrator_action == \"suggest_locations\":\n",
    "        #########################\n",
    "        current_step = \"received_location\"\n",
    "    elif orchestrator_action == \"answer_questions\":\n",
    "        current_step = \"ask_lock_location\"\n",
    "    elif orchestrator_action == \"bad_weather\":\n",
    "        current_step = \"lock_or_change\"\n",
    "    elif orchestrator_action == \"lock_location\":\n",
    "        current_step = \"end_or_suggest_alternatives\"\n",
    "\n",
    "    elif orchestrator_action == \"suggest_alternatives\":\n",
    "        current_step = \"suggest_other_locations\"\n",
    "    elif orchestrator_action == \"end_conversation\":\n",
    "        current_step = \"return_list_of_locked_locations\"\n",
    "    elif orchestrator_action == \"give_list\":  \n",
    "        current_step = \"end\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
